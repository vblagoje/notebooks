{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPE9TyioiaYc0MOVO7Z5Wlu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vblagoje/notebooks/blob/main/haystack2x-demos/haystack_rag_serperdev_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Introduction\n",
        "\n",
        "This notebook showcases the upcoming Haystack OpenAPI service-based Retriever-Augmented Generation (RAG). Given a user query, we search the web for the results of the query and inject these results into LLM contenxt along with the system prompt."
      ],
      "metadata": {
        "id": "J8TDTtQwiSn6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Setup\n",
        "\n",
        "Let's install necessary libraries and import key modules to build the foundation for the subsequent steps."
      ],
      "metadata": {
        "id": "6zUWNgF-kUeU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y llmx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mTo7qxZa_02g",
        "outputId": "6c0c9113-32c0-4af9-87fc-07365a9b40f8"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: llmx 0.0.15a0\n",
            "Uninstalling llmx-0.0.15a0:\n",
            "  Successfully uninstalled llmx-0.0.15a0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q openapi3 jsonref"
      ],
      "metadata": {
        "id": "bH8Lo7PSumLG"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q git+https://github.com/deepset-ai/haystack.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZkB9-FamGO7C",
        "outputId": "b4f774f7-96a6-4da4-a2b2-44d71bc0f400"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.0/77.0 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for haystack-ai (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "import os\n",
        "import json\n",
        "import requests\n",
        "\n",
        "from haystack import Pipeline\n",
        "from haystack.components.generators.utils import default_streaming_callback\n",
        "from haystack.components.converters import OpenAPIServiceToFunctions\n",
        "from haystack.components.generators.chat import GPTChatGenerator\n",
        "from haystack.components.connectors import OpenAPIServiceConnector\n",
        "from haystack.dataclasses import ChatMessage"
      ],
      "metadata": {
        "id": "RhxdVLCb_D8R"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Prepare SerperDev service along with system prompt\n",
        "\n",
        "- Generate OpenAI functions definitions for SerperDev"
      ],
      "metadata": {
        "id": "m-Po2hm0kzKj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gen_func_pipeline = Pipeline()\n",
        "gen_func_pipeline.add_component(\"spec_to_functions\", OpenAPIServiceToFunctions())"
      ],
      "metadata": {
        "id": "rXrLxTQ8Dl8V"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "functions_result = gen_func_pipeline.run(data={\"sources\":[\"https://bit.ly/3NIJqnd\"],\n",
        "                                               \"system_messages\":[requests.get(\"https://bit.ly/3TdHsyB\").text]})"
      ],
      "metadata": {
        "id": "F7rKAns3Do6Q"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. API keys, set up simple authentication mechanism"
      ],
      "metadata": {
        "id": "JTZRxFD5lX7N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm_api_key = getpass.getpass(\"Enter LLM provider api key:\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lNGXm479JSr4",
        "outputId": "f711c2e6-2c6e-4001-bef5-817fc2663efb"
      },
      "execution_count": 9,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter LLM provider api key:··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "serper_dev_key = getpass.getpass(\"Enter serperdev api key:\")\n",
        "services_auth = {\"SerperDev\":serper_dev_key}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uqGsQrRYJZ-2",
        "outputId": "238aa4a6-f0f3-4f62-9d89-a6126a3baed3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter serperdev api key:··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Retrieval step - SerperDev service invocation"
      ],
      "metadata": {
        "id": "X4uOPWS-lq2J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "invoke_service_pipe = Pipeline()\n",
        "invoke_service_pipe.add_component(\"functions_llm\", GPTChatGenerator(api_key=llm_api_key, model_name=\"gpt-3.5-turbo-0613\"))\n",
        "invoke_service_pipe.add_component(\"openapi_container\", OpenAPIServiceConnector(services_auth))\n",
        "invoke_service_pipe.connect(\"functions_llm.replies\", \"openapi_container.messages\")"
      ],
      "metadata": {
        "id": "L7MZib9gJ4j-"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_prompt = \"Why was Sam Altman ousted from OpenAI?\"\n"
      ],
      "metadata": {
        "id": "AF25DrntJ1mP"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "service_desc_document = functions_result[\"spec_to_functions\"][\"documents\"][0]\n",
        "openai_functions_definition = json.loads(service_desc_document.content)\n",
        "openapi_spec = service_desc_document.meta[\"spec\"]\n",
        "\n",
        "service_response = invoke_service_pipe.run(data={\"messages\":[ChatMessage.from_user(user_prompt)],\n",
        "                                                 \"generation_kwargs\": {\"functions\": [openai_functions_definition]},\n",
        "                                                 \"service_openapi_spec\": openapi_spec})"
      ],
      "metadata": {
        "id": "OHP2Nj79KCdQ"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Generate LLM response\n",
        "\n",
        "Inject service response into LLM context, pair it with system prompt"
      ],
      "metadata": {
        "id": "S9pPCVzwmHpj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gen_pipe = Pipeline()\n",
        "llm = GPTChatGenerator(api_key=llm_api_key, model_name=\"gpt-4-1106-preview\", streaming_callback=default_streaming_callback)\n",
        "gen_pipe.add_component(\"llm\", llm)\n",
        "\n",
        "github_pr_prompt_messages = [ChatMessage.from_system(service_desc_document.meta[\"system_message\"])] + service_response[\"openapi_container\"][\"service_response\"]\n",
        "final_result = gen_pipe.run(data={\"messages\": github_pr_prompt_messages})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CnYwWtYSKFl0",
        "outputId": "2cccf727-667e-4634-dffc-ffefd7e830b6"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sam Altman was ousted from OpenAI because, according to new reports, he may have been a manipulative leader. These reports suggest that he pitted board members and employees against each other to maintain power."
          ]
        }
      ]
    }
  ]
}