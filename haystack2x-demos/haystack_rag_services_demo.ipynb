{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNi5PpXNLkdd72vwKN00pEr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vblagoje/notebooks/blob/main/haystack2x-demos/haystack_rag_services_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Introduction\n",
        "\n",
        "This notebook showcases a novel application of Qdrant vector DB in the upcoming Haystack OpenAPI service-based Retriever-Augmented Generation (RAG) system. Given a user query, we retrieve the corresponding OpenAPI specification from Qdrant vector DB. The retrieved service specification is then seamlessly injected into the Haystack pipeline, enabling the dynamic invocation of selected API services. This innovative approach, integrating any OpenAPI spec service with LLMs, opens a new era for RAG systems to generate contextually rich responses from any openapi service."
      ],
      "metadata": {
        "id": "J8TDTtQwiSn6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Setup\n",
        "This notebook demos Haystack 2.x service based RAG, using two openapi services: GitHub's compare_branches and SerperDev search API.\n",
        "\n",
        "Let's install necessary libraries and import key modules to build the foundation for the subsequent steps."
      ],
      "metadata": {
        "id": "6zUWNgF-kUeU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q \"grpcio-tools==1.42\" sentence-transformers openapi3 jsonref qdrant-haystack git+https://github.com/deepset-ai/haystack.git"
      ],
      "metadata": {
        "id": "bH8Lo7PSumLG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "import os\n",
        "import json\n",
        "import requests\n",
        "from typing import List, Dict, Any\n",
        "from haystack_integrations.document_stores.qdrant import QdrantDocumentStore\n",
        "from haystack_integrations.components.retrievers.qdrant import QdrantEmbeddingRetriever\n",
        "\n",
        "from haystack import Pipeline, Document\n",
        "from haystack.components.generators.utils import print_streaming_chunk\n",
        "from haystack.components.writers import DocumentWriter\n",
        "from haystack.components.embedders import SentenceTransformersDocumentEmbedder\n",
        "from haystack.components.converters import OpenAPIServiceToFunctions, OutputAdapter\n",
        "from haystack.components.embedders import SentenceTransformersTextEmbedder\n",
        "from haystack.components.generators.chat import OpenAIChatGenerator\n",
        "from haystack.components.connectors import OpenAPIServiceConnector\n",
        "from haystack.components.fetchers import LinkContentFetcher\n",
        "from haystack.components.others import Multiplexer\n",
        "from haystack.dataclasses import ChatMessage, ByteStream"
      ],
      "metadata": {
        "id": "RhxdVLCb_D8R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Setting up Qdrant vector DB, create indexing pipeline"
      ],
      "metadata": {
        "id": "m-Po2hm0kzKj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "document_store = QdrantDocumentStore(\n",
        "    path=\"./qdrant_23\",\n",
        "    index=\"Document\",\n",
        "    embedding_dim=768,\n",
        "    recreate_index=True\n",
        "  )"
      ],
      "metadata": {
        "id": "mmVOQAg-C9Zx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_docs(functions, specs, system_messages, service_credentials):\n",
        "  docs = []\n",
        "  for function, spec, system_message, service_credential in zip(functions, specs, system_messages, service_credentials):\n",
        "    d = Document(content=json.dumps(function),\n",
        "                 meta={\"spec\": json.dumps(spec),\n",
        "                       \"system_message\": system_message,\n",
        "                       \"service_credential\": service_credential})\n",
        "    print(d.meta)\n",
        "    docs.append(d)\n",
        "  return docs"
      ],
      "metadata": {
        "id": "7U-QKL3nyhX0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "indexing_pipeline = Pipeline()\n",
        "indexing_pipeline.add_component(\"fetcher\", LinkContentFetcher())\n",
        "indexing_pipeline.add_component(\"mx\", Multiplexer(List[ByteStream]))\n",
        "indexing_pipeline.add_component(\"spec_to_functions\", OpenAPIServiceToFunctions())\n",
        "indexing_pipeline.add_component(\"embedder\", SentenceTransformersDocumentEmbedder(model=\"sentence-transformers/all-mpnet-base-v2\",\n",
        "                                                                                 meta_fields_to_embed=[\"spec\", \"system_message\", \"service_credential\"]))\n",
        "indexing_pipeline.add_component(\"writer\", DocumentWriter(document_store=document_store))\n",
        "indexing_pipeline.add_component(\"a1\", OutputAdapter(\"{{functions | create_docs(specs, system_messages, service_credentials)}}\",\n",
        "                                                     List[Document],\n",
        "                                                      {\"create_docs\": create_docs}))\n",
        "\n",
        "indexing_pipeline.add_component(\"a2\", OutputAdapter(\"{{sources | json_objects}}\",\n",
        "                                                     List[Dict[str, Any]],\n",
        "                                                      {\"json_objects\": lambda sources: [json.loads(s.to_string()) for s in sources]}))\n",
        "\n",
        "indexing_pipeline.connect(sender=\"fetcher.streams\", receiver=\"mx\")\n",
        "indexing_pipeline.connect(sender=\"mx\", receiver=\"spec_to_functions.sources\")\n",
        "indexing_pipeline.connect(sender=\"mx\", receiver=\"a2.sources\")\n",
        "indexing_pipeline.connect(sender=\"a2\", receiver=\"a1.specs\")\n",
        "indexing_pipeline.connect(sender=\"spec_to_functions.functions\", receiver=\"a1\")\n",
        "indexing_pipeline.connect(sender=\"a1.output\", receiver=\"embedder.documents\")\n",
        "indexing_pipeline.connect(sender=\"embedder\", receiver=\"writer\")"
      ],
      "metadata": {
        "id": "rXrLxTQ8Dl8V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "serper_dev_key = getpass.getpass(\"Enter serperdev api key:\")\n",
        "github_token = getpass.getpass(\"Enter your github token:\")\n",
        "\n",
        "services_auth = {\"SerperDev\":serper_dev_key, \"Github API\": github_token}"
      ],
      "metadata": {
        "id": "uqGsQrRYJZ-2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Index two openapi specs (Github and SerperDev), along with system prompts"
      ],
      "metadata": {
        "id": "iz57DpxelJKn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result = indexing_pipeline.run(data={\"fetcher\": {\"urls\":[\"https://bit.ly/github_compare\",\"https://bit.ly/serper_dev_spec\"]},\n",
        "                                     \"a1\":{\"service_credentials\": [github_token, serper_dev_key],\n",
        "                                           \"system_messages\": [requests.get(\"https://bit.ly/pr_auto_system\").text, requests.get(\"https://bit.ly/serper_dev_system_prompt\").text]\n",
        "                                           }\n",
        "                                     })"
      ],
      "metadata": {
        "id": "F7rKAns3Do6Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result[\"writer\"]"
      ],
      "metadata": {
        "id": "UoPd9EJItlU1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retrieval_pipeline = Pipeline()\n",
        "retrieval_pipeline.add_component(\"embedder\", SentenceTransformersTextEmbedder(model=\"sentence-transformers/all-mpnet-base-v2\"))\n",
        "retrieval_pipeline.add_component(\"retriever\", QdrantEmbeddingRetriever(document_store=document_store))\n",
        "retrieval_pipeline.connect(sender=\"embedder\", receiver=\"retriever\")"
      ],
      "metadata": {
        "id": "hsKX5IJDJLXo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. API keys, set up simple authentication mechanism"
      ],
      "metadata": {
        "id": "JTZRxFD5lX7N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm_api_key = getpass.getpass(\"Enter LLM provider api key:\")\n"
      ],
      "metadata": {
        "id": "lNGXm479JSr4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Retrieval step - service invocation\n",
        "\n",
        "Based on the prompt, retrieve the right service spec from Qdrant, inject spec and system prompt into the pipeline"
      ],
      "metadata": {
        "id": "X4uOPWS-lq2J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from haystack.utils import Secret\n",
        "\n",
        "invoke_service_pipe = Pipeline()\n",
        "invoke_service_pipe.add_component(\"functions_llm\", OpenAIChatGenerator(api_key=Secret.from_token(llm_api_key), model=\"gpt-3.5-turbo-0613\"))\n",
        "invoke_service_pipe.add_component(\"openapi_container\", OpenAPIServiceConnector())\n",
        "invoke_service_pipe.connect(\"functions_llm.replies\", \"openapi_container.messages\")"
      ],
      "metadata": {
        "id": "L7MZib9gJ4j-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_prompt = \"Search web and tell me why was Sam Altman ousted from OpenAI\"\n",
        "user_prompt = \"Compare branches main and test/benchmarks2.0, in project deepset-ai, repo haystack\""
      ],
      "metadata": {
        "id": "AF25DrntJ1mP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "top_k = 1\n",
        "top_k_result = retrieval_pipeline.run(data={\"text\": user_prompt, \"top_k\": top_k})\n",
        "top_k_docs = top_k_result[\"retriever\"][\"documents\"][:top_k]"
      ],
      "metadata": {
        "id": "3z568P4FJ_XU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "top_1 = top_k_docs[0]\n",
        "openai_functions_definition = json.loads(top_1.content)\n",
        "\n",
        "tools_param = [{\"type\": \"function\", \"function\": openai_functions_definition}]\n",
        "tool_choice = {\"type\": \"function\", \"function\": {\"name\": openai_functions_definition[\"name\"]}}\n",
        "\n",
        "service_response = invoke_service_pipe.run(data={\"messages\":[ChatMessage.from_user(user_prompt)],\n",
        "                                                 \"generation_kwargs\": {\"tools\": tools_param,\n",
        "                                                                       \"tool_choice\": tool_choice},\n",
        "                                                 \"service_openapi_spec\": json.loads(top_1.meta[\"spec\"]),\n",
        "                                                 \"service_credentials\": top_1.meta[\"service_credential\"]})"
      ],
      "metadata": {
        "id": "OHP2Nj79KCdQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Generate LLM response\n",
        "\n",
        "Inject service response into LLM context, pair it with system prompt"
      ],
      "metadata": {
        "id": "S9pPCVzwmHpj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gen_pipe = Pipeline()\n",
        "llm = OpenAIChatGenerator(api_key=Secret.from_token(llm_api_key), model=\"gpt-4-1106-preview\", streaming_callback=print_streaming_chunk)\n",
        "gen_pipe.add_component(\"llm\", llm)\n",
        "\n",
        "github_pr_prompt_messages = [ChatMessage.from_system(top_1.meta[\"system_message\"])] + service_response[\"openapi_container\"][\"service_response\"]\n",
        "final_result = gen_pipe.run(data={\"messages\": github_pr_prompt_messages})"
      ],
      "metadata": {
        "id": "CnYwWtYSKFl0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, Markdown\n",
        "display(Markdown(final_result[\"llm\"][\"replies\"][0].content))\n"
      ],
      "metadata": {
        "id": "H64OuyRwM_PD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Thank you, questions?\n",
        "\n",
        "<a href=\"www.qr-code-generator.com/\" border=\"0\" style=\"cursor:default\" rel=\"nofollow\"><img src=\"https://chart.googleapis.com/chart?cht=qr&chl=https%3A%2F%2Fgithub.com%2Fvblagoje%2Fnotebooks%2Fblob%2Fmain%2Fhaystack2x-demos%2Fhaystack_rag_services_demo.ipynb&chs=180x180&choe=UTF-8&chld=L|2\"></a>"
      ],
      "metadata": {
        "id": "PLVhdFF06_p5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Links:\n",
        "- https://github.com/deepset-ai/haystack/\n",
        "- https://haystack.deepset.ai/community\n",
        "- https://haystack.deepset.ai/advent-of-haystack\n",
        "- https://x.com/vladblagoje"
      ],
      "metadata": {
        "id": "sD3JS7ds7IJ2"
      }
    }
  ]
}