{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPZgSzFXjvwasFDZkLNMAsJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "727ac8e160d7496798e933339c0a3717": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f02a3809b49848d385c9ff43e46b373c",
              "IPY_MODEL_96fda8f0848945cfac3be7f342e0251c",
              "IPY_MODEL_483b05cba005468d82dcd10fdc4e0c18"
            ],
            "layout": "IPY_MODEL_6faaac78da1845379854a0e3f2341837"
          }
        },
        "f02a3809b49848d385c9ff43e46b373c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8176aa5e923d48e09d440e108183eb3f",
            "placeholder": "​",
            "style": "IPY_MODEL_55686910879542aa9bbb87a99d624135",
            "value": "Batches: 100%"
          }
        },
        "96fda8f0848945cfac3be7f342e0251c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e8b07b46251f42998903d7c2f11bbad7",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a8faa15d12fb4fa49ae9b0be79ef7c71",
            "value": 1
          }
        },
        "483b05cba005468d82dcd10fdc4e0c18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_770f92b463db4c998d4ef658eeaed052",
            "placeholder": "​",
            "style": "IPY_MODEL_fbf2d08c99e84c7fb4ca9ddd0737321d",
            "value": " 1/1 [00:00&lt;00:00,  6.43it/s]"
          }
        },
        "6faaac78da1845379854a0e3f2341837": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8176aa5e923d48e09d440e108183eb3f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "55686910879542aa9bbb87a99d624135": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e8b07b46251f42998903d7c2f11bbad7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a8faa15d12fb4fa49ae9b0be79ef7c71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "770f92b463db4c998d4ef658eeaed052": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fbf2d08c99e84c7fb4ca9ddd0737321d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vblagoje/notebooks/blob/main/haystack2x-demos/haystack_rag_services_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install virtualenv\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nOt0Tz2QHfkq",
        "outputId": "61306b83-4956-4c1f-cbf3-2d0d2e64603c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting virtualenv\n",
            "  Downloading virtualenv-20.25.0-py3-none-any.whl (3.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m43.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting distlib<1,>=0.3.7 (from virtualenv)\n",
            "  Downloading distlib-0.3.7-py2.py3-none-any.whl (468 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.9/468.9 kB\u001b[0m \u001b[31m42.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock<4,>=3.12.2 in /usr/local/lib/python3.10/dist-packages (from virtualenv) (3.13.1)\n",
            "Requirement already satisfied: platformdirs<5,>=3.9.1 in /usr/local/lib/python3.10/dist-packages (from virtualenv) (4.0.0)\n",
            "Installing collected packages: distlib, virtualenv\n",
            "Successfully installed distlib-0.3.7 virtualenv-20.25.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!virtualenv rag_services_demo\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ujws8AndHj9L",
        "outputId": "e163cff8-f133-4f23-8eb5-1a8ef34ab98d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "created virtual environment CPython3.10.12.final.0-64 in 1102ms\n",
            "  creator CPython3Posix(dest=/content/rag_services_demo, clear=False, no_vcs_ignore=False, global=False)\n",
            "  seeder FromAppData(download=False, pip=bundle, setuptools=bundle, wheel=bundle, via=copy, app_data_dir=/root/.local/share/virtualenv)\n",
            "    added seed packages: pip==23.3.1, setuptools==69.0.2, wheel==0.42.0\n",
            "  activators BashActivator,CShellActivator,FishActivator,NushellActivator,PowerShellActivator,PythonActivator\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!source rag_services_demo/bin/activate"
      ],
      "metadata": {
        "id": "wUcBNdBSHsKs"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y llmx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mTo7qxZa_02g",
        "outputId": "84d65fef-41c3-4e41-b107-4c700decf4ff"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: llmx 0.0.15a0\n",
            "Uninstalling llmx-0.0.15a0:\n",
            "  Successfully uninstalled llmx-0.0.15a0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q git+https://github.com/deepset-ai/haystack.git@openapi_container_v5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KERj7pDJF2sv",
        "outputId": "2032ceaa-39e8-43ae-c69d-8f07a45f3dd6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.0/77.0 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for haystack-ai (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q sentence-transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K32q04vrDt-W",
        "outputId": "1128271b-99b5-47f6-d088-fabeb8df5b16"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/86.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openapi3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1WKGztabHJXb",
        "outputId": "544c2d6a-5993-4ce5-8955-c9a51992c318"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openapi3\n",
            "  Downloading openapi3-1.8.2-py2.py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: PyYaml in /usr/local/lib/python3.10/dist-packages (from openapi3) (6.0.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from openapi3) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->openapi3) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->openapi3) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->openapi3) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->openapi3) (2023.11.17)\n",
            "Installing collected packages: openapi3\n",
            "Successfully installed openapi3-1.8.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install jsonref"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yKOzyRUSHF3D",
        "outputId": "f8e9c92d-51bd-4841-f32f-b5572431bda5"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting jsonref\n",
            "  Downloading jsonref-1.1.0-py3-none-any.whl (9.4 kB)\n",
            "Installing collected packages: jsonref\n",
            "Successfully installed jsonref-1.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q git+https://github.com/qdrant/qdrant-haystack.git@haystack-v2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZkB9-FamGO7C",
        "outputId": "91815e95-ac01-4982-b924-42847f60e10b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m182.2/182.2 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m670.2/670.2 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m80.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.8/143.8 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m50.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m55.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m76.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.8/209.8 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.5/20.5 MB\u001b[0m \u001b[31m83.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m33.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for qdrant-haystack (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-metadata 1.14.0 requires protobuf<4.21,>=3.20.3, but you have protobuf 4.25.1 which is incompatible.\n",
            "torchaudio 2.1.0+cu118 requires torch==2.1.0, but you have torch 2.1.1 which is incompatible.\n",
            "torchdata 0.7.0 requires torch==2.1.0, but you have torch 2.1.1 which is incompatible.\n",
            "torchtext 0.16.0 requires torch==2.1.0, but you have torch 2.1.1 which is incompatible.\n",
            "torchvision 0.16.0+cu118 requires torch==2.1.0, but you have torch 2.1.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "import os\n",
        "import json\n",
        "import requests\n",
        "from qdrant_haystack import QdrantDocumentStore\n",
        "from qdrant_haystack.retriever import QdrantRetriever\n",
        "\n",
        "from haystack import Pipeline\n",
        "from haystack.components.generators.utils import default_streaming_callback\n",
        "from haystack.components.writers import DocumentWriter\n",
        "from haystack.components.embedders import SentenceTransformersDocumentEmbedder\n",
        "from haystack.components.converters import OpenAPIServiceToFunctions\n",
        "from haystack.components.embedders import SentenceTransformersTextEmbedder\n",
        "from haystack.components.generators.chat import GPTChatGenerator\n",
        "from haystack.components.connectors import OpenAPIServiceConnector\n",
        "from haystack.dataclasses import ChatMessage"
      ],
      "metadata": {
        "id": "RhxdVLCb_D8R"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "document_store = QdrantDocumentStore(\n",
        "    path=\"./qdrant_v1\",\n",
        "    index=\"Document\",\n",
        "    embedding_dim=768,\n",
        "    recreate_index=True,\n",
        "    hnsw_config={\"m\": 16, \"ef_construct\": 64}  # Optional\n",
        ")"
      ],
      "metadata": {
        "id": "mmVOQAg-C9Zx"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "indexing_pipeline = Pipeline()\n",
        "indexing_pipeline.add_component(\"spec_to_functions\", OpenAPIServiceToFunctions())\n",
        "indexing_pipeline.add_component(\"embedder\", SentenceTransformersDocumentEmbedder(model_name_or_path=\"sentence-transformers/all-mpnet-base-v2\"))\n",
        "indexing_pipeline.add_component(\"writer\", DocumentWriter(document_store=document_store))\n",
        "indexing_pipeline.connect(connect_from=\"spec_to_functions\", connect_to=\"embedder\")\n",
        "indexing_pipeline.connect(connect_from=\"embedder\", connect_to=\"writer\")"
      ],
      "metadata": {
        "id": "rXrLxTQ8Dl8V"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "indexing_pipeline.run(data={\"sources\":[\"https://t.ly/eBODl\", \"https://t.ly/Cn-Tv\"],\n",
        "                            \"system_messages\":[requests.get(\"https://t.ly/_1vOw\").text,\n",
        "                                               requests.get(\"https://t.ly/fZR09\").text]})"
      ],
      "metadata": {
        "id": "F7rKAns3Do6Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retrieval_pipeline = Pipeline()\n",
        "retrieval_pipeline.add_component(\"embedder\", SentenceTransformersTextEmbedder(model_name_or_path=\"sentence-transformers/all-mpnet-base-v2\"))\n",
        "retrieval_pipeline.add_component(\"retriever\", QdrantRetriever(document_store=document_store))\n",
        "retrieval_pipeline.connect(connect_from=\"embedder\", connect_to=\"retriever\")"
      ],
      "metadata": {
        "id": "hsKX5IJDJLXo"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm_api_key = getpass.getpass(\"Enter LLM provider api key:\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lNGXm479JSr4",
        "outputId": "93863f7e-c15d-4f22-c97d-7da0dd655efb"
      },
      "execution_count": 16,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter LLM provider api key:··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "serper_dev_key = getpass.getpass(\"Enter serperdev api key:\")\n",
        "services_auth = {\"SerperDev\":serper_dev_key}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uqGsQrRYJZ-2",
        "outputId": "6a3d6778-6593-44e1-f1be-0c0d44f261ce"
      },
      "execution_count": 18,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter serperdev api key:··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "invoke_service_pipe = Pipeline()\n",
        "invoke_service_pipe.add_component(\"functions_llm\", GPTChatGenerator(api_key=llm_api_key, model_name=\"gpt-3.5-turbo-0613\"))\n",
        "invoke_service_pipe.add_component(\"openapi_container\", OpenAPIServiceConnector(services_auth))\n",
        "invoke_service_pipe.connect(\"functions_llm.replies\", \"openapi_container.messages\")"
      ],
      "metadata": {
        "id": "L7MZib9gJ4j-"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_prompt = \"Search web and tell me why was Sam Altman ousted from OpenAI\"\n",
        "user_prompt = \"Compare branches main and openapi_container_v5, in project deepset-ai, repo haystack\""
      ],
      "metadata": {
        "id": "AF25DrntJ1mP"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "top_k = 1\n",
        "top_k_result = retrieval_pipeline.run(data={\"text\": user_prompt, \"top_k\": top_k})\n",
        "top_k_docs = top_k_result[\"retriever\"][\"documents\"][:top_k]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "727ac8e160d7496798e933339c0a3717",
            "f02a3809b49848d385c9ff43e46b373c",
            "96fda8f0848945cfac3be7f342e0251c",
            "483b05cba005468d82dcd10fdc4e0c18",
            "6faaac78da1845379854a0e3f2341837",
            "8176aa5e923d48e09d440e108183eb3f",
            "55686910879542aa9bbb87a99d624135",
            "e8b07b46251f42998903d7c2f11bbad7",
            "a8faa15d12fb4fa49ae9b0be79ef7c71",
            "770f92b463db4c998d4ef658eeaed052",
            "fbf2d08c99e84c7fb4ca9ddd0737321d"
          ]
        },
        "id": "3z568P4FJ_XU",
        "outputId": "12e56d4e-e8f9-4377-cb8c-6e6276f9456b"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "727ac8e160d7496798e933339c0a3717"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "top_1_document = top_k_docs[0]\n",
        "openai_functions_definition = json.loads(top_1_document.content)\n",
        "openapi_spec = top_1_document.meta[\"spec\"]\n",
        "messages = [ChatMessage.from_user(user_prompt)]\n",
        "\n",
        "service_response = invoke_service_pipe.run(data={\"messages\":[ChatMessage.from_user(user_prompt)],\n",
        "                                                 \"generation_kwargs\": {\"functions\": [openai_functions_definition]},\n",
        "                                                 \"service_openapi_spec\": openapi_spec})"
      ],
      "metadata": {
        "id": "OHP2Nj79KCdQ"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gen_pipe = Pipeline()\n",
        "llm = GPTChatGenerator(api_key=llm_api_key, model_name=\"gpt-4-1106-preview\", streaming_callback=default_streaming_callback)\n",
        "gen_pipe.add_component(\"llm\", llm)\n",
        "\n",
        "github_pr_prompt_messages = [ChatMessage.from_system(top_1_document.meta[\"system_message\"])] + service_response[\"openapi_container\"][\"service_response\"]\n",
        "final_result = gen_pipe.run(data={\"messages\": github_pr_prompt_messages})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CnYwWtYSKFl0",
        "outputId": "600d3869-7fed-492f-ca2d-f0b1b0c80208"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### Why:\n",
            "The proposed changes aim to enhance the haystack library by introducing new components for interacting with OpenAPI services. These components extend the functionality of the library to allow it to connect to external services described by OpenAPI specifications, enabling the invocation of those services' methods directly through the framework.\n",
            "\n",
            "### What:\n",
            "The pull request consists of the following key additions:\n",
            "\n",
            "1. `OpenAPIServiceConnector`: This component allows the haystack framework to connect to and interact with services that provide an OpenAPI specification. It enables the execution of service methods based on the content of chat messages that follow a specific JSON structure.\n",
            "\n",
            "2. `OpenAPIServiceToFunctions`: This converter component processes an OpenAPI specification to extract definitions that can be called via the OpenAI function-calling mechanism.\n",
            "\n",
            "The changes also include updates to the `__init__.py` files in the `connectors` and `converters` modules to expose the new components.\n",
            "\n",
            "### How can it be used:\n",
            "Developers can use the `OpenAPIServiceConnector` component to expand the capabilities of their applications built with the haystack framework by programmatically interacting with OpenAPI services. By passing messages to the service connector, developers can invoke specific methods and receive responses that are integrated back into the chat workflow.\n",
            "\n",
            "The `OpenAPIServiceToFunctions` component can be used to prepare OpenAPI service specifications for use with OpenAI's function calling capabilities, opening up the possibility of integrating a diverse range of services with OpenAI workflows.\n",
            "\n",
            "### How did you test it:\n",
            "Given that the pull request does not include explicit test cases or outcomes, my analysis is limited to the provided changes. However, the typical way to test these additions would involve the following steps:\n",
            "\n",
            "1. Unit tests to validate that the classes correctly parse messages, handle authentication, and interact with mock OpenAPI services as expected.\n",
            "2. Integration tests that interact with actual OpenAPI services to verify the end-to-end functionality, including error handling and response formatting.\n",
            "3. Examples or documentation providing usage scenarios to help validate that the components work as intended in real-world applications.\n",
            "\n",
            "If test cases have been executed, the author should provide information on which tests were conducted, any mock services used, the results obtained, and how developers can replicate the testing process.\n",
            "\n",
            "### Notes for the reviewer:\n",
            "The reviewer should ensure that the new components adhere to the design principles of the haystack ecosystem and are compatible with existing components. They should review the error handling, particularly how the components manage invalid JSON payloads and authentication failures. Furthermore, it's important to ensure that the implementation handles OpenAPI specifications correctly, including resolving references and extracting the necessary information for function calls.\n",
            "\n",
            "Since the actual tests are not included in the pull request, it would be beneficial for the reviewer to request test cases or examples demonstrating the use of these components within the haystack framework. Additionally, documentation updates explaining how to integrate these new components into existing applications using the haystack framework would be valuable for end-users."
          ]
        }
      ]
    }
  ]
}