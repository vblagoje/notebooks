{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNRZ7SZSOI+kDybs38ENEg3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "683c205f5cd24df5aa62b64047c8a6ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_61da958809274b469742694e5a043f25",
              "IPY_MODEL_34c692e4bfbc46189bb53a794e449734",
              "IPY_MODEL_c56bac068a254edb95b9a955527eb5c3"
            ],
            "layout": "IPY_MODEL_4d0909e27c7e499d92870a056fa3a086"
          }
        },
        "61da958809274b469742694e5a043f25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9a91fcb7874e4dd78b0a9a07ce6e8844",
            "placeholder": "​",
            "style": "IPY_MODEL_2cc30b34a73e4638a2b21e8259417414",
            "value": "Batches: 100%"
          }
        },
        "34c692e4bfbc46189bb53a794e449734": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7966660b155741d0b0c26d806d5e4c6a",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_302e10f5434e424fb74453984255733b",
            "value": 1
          }
        },
        "c56bac068a254edb95b9a955527eb5c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_48baef18d7c74d29856830904fdc8894",
            "placeholder": "​",
            "style": "IPY_MODEL_ce9b6ad2b7874f0e81582d17a23366dc",
            "value": " 1/1 [00:00&lt;00:00,  7.98it/s]"
          }
        },
        "4d0909e27c7e499d92870a056fa3a086": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a91fcb7874e4dd78b0a9a07ce6e8844": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2cc30b34a73e4638a2b21e8259417414": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7966660b155741d0b0c26d806d5e4c6a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "302e10f5434e424fb74453984255733b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "48baef18d7c74d29856830904fdc8894": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce9b6ad2b7874f0e81582d17a23366dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vblagoje/notebooks/blob/main/haystack2x-demos/haystack_rag_services_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Introduction\n",
        "\n",
        "This notebook showcases a novel application of Qdrant vector DB in the upcoming Haystack OpenAPI service-based Retriever-Augmented Generation (RAG) system. Given a user query, we retrieve the corresponding OpenAPI specification from Qdrant vector DB. The retrieved service specification is then seamlessly injected into the Haystack pipeline, enabling the dynamic invocation of selected API services. This innovative approach, integrating any OpenAPI spec service with LLMs, opens a new era for RAG systems to generate contextually rich responses from any openapi service."
      ],
      "metadata": {
        "id": "J8TDTtQwiSn6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Setup\n",
        "This notebook demos Haystack 2.x service based RAG, using two openapi services: GitHub's compare_branches and SerperDev search API.\n",
        "\n",
        "Let's install necessary libraries and import key modules to build the foundation for the subsequent steps."
      ],
      "metadata": {
        "id": "6zUWNgF-kUeU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y llmx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mTo7qxZa_02g",
        "outputId": "e1fef0f1-337c-43f1-8dbd-9099cadc2b45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: llmx 0.0.15a0\n",
            "Uninstalling llmx-0.0.15a0:\n",
            "  Successfully uninstalled llmx-0.0.15a0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q \"grpcio-tools==1.42\" sentence-transformers openapi3 jsonref"
      ],
      "metadata": {
        "id": "bH8Lo7PSumLG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q git+https://github.com/vblagoje/qdrant-haystack.git@haystack-v2 git+https://github.com/deepset-ai/haystack.git@openapi_container_v5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZkB9-FamGO7C",
        "outputId": "6d4a1d11-21a9-4165-e9a6-c515c14a6035"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m182.2/182.2 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.0/77.0 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.8/143.8 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for qdrant-haystack (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for haystack-ai (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "import os\n",
        "import json\n",
        "import requests\n",
        "from qdrant_haystack import QdrantDocumentStore\n",
        "from qdrant_haystack.retriever import QdrantRetriever\n",
        "\n",
        "from haystack import Pipeline\n",
        "from haystack.components.generators.utils import default_streaming_callback\n",
        "from haystack.components.writers import DocumentWriter\n",
        "from haystack.components.embedders import SentenceTransformersDocumentEmbedder\n",
        "from haystack.components.converters import OpenAPIServiceToFunctions\n",
        "from haystack.components.embedders import SentenceTransformersTextEmbedder\n",
        "from haystack.components.generators.chat import GPTChatGenerator\n",
        "from haystack.components.connectors import OpenAPIServiceConnector\n",
        "from haystack.dataclasses import ChatMessage"
      ],
      "metadata": {
        "id": "RhxdVLCb_D8R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Setting up Qdrant vector DB, create indexing pipeline"
      ],
      "metadata": {
        "id": "m-Po2hm0kzKj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "document_store = QdrantDocumentStore(\n",
        "    path=\"./qdrant_v1\",\n",
        "    index=\"Document\",\n",
        "    embedding_dim=768,\n",
        "    recreate_index=True,\n",
        "    hnsw_config={\"m\": 16, \"ef_construct\": 64}  # Optional\n",
        ")"
      ],
      "metadata": {
        "id": "mmVOQAg-C9Zx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "indexing_pipeline = Pipeline()\n",
        "indexing_pipeline.add_component(\"spec_to_functions\", OpenAPIServiceToFunctions())\n",
        "indexing_pipeline.add_component(\"embedder\", SentenceTransformersDocumentEmbedder(model_name_or_path=\"sentence-transformers/all-mpnet-base-v2\"))\n",
        "indexing_pipeline.add_component(\"writer\", DocumentWriter(document_store=document_store))\n",
        "indexing_pipeline.connect(connect_from=\"spec_to_functions\", connect_to=\"embedder\")\n",
        "indexing_pipeline.connect(connect_from=\"embedder\", connect_to=\"writer\")"
      ],
      "metadata": {
        "id": "rXrLxTQ8Dl8V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Index two openapi specs (Github and SerperDev), along with system prompts"
      ],
      "metadata": {
        "id": "iz57DpxelJKn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "indexing_pipeline.run(data={\"sources\":[\"https://t.ly/eBODl\", \"https://t.ly/Cn-Tv\"],\n",
        "                            \"system_messages\":[requests.get(\"https://t.ly/_1vOw\").text,\n",
        "                                               requests.get(\"https://t.ly/fZR09\").text]})"
      ],
      "metadata": {
        "id": "F7rKAns3Do6Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retrieval_pipeline = Pipeline()\n",
        "retrieval_pipeline.add_component(\"embedder\", SentenceTransformersTextEmbedder(model_name_or_path=\"sentence-transformers/all-mpnet-base-v2\"))\n",
        "retrieval_pipeline.add_component(\"retriever\", QdrantRetriever(document_store=document_store))\n",
        "retrieval_pipeline.connect(connect_from=\"embedder\", connect_to=\"retriever\")"
      ],
      "metadata": {
        "id": "hsKX5IJDJLXo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. API keys, set up simple authentication mechanism"
      ],
      "metadata": {
        "id": "JTZRxFD5lX7N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm_api_key = getpass.getpass(\"Enter LLM provider api key:\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lNGXm479JSr4",
        "outputId": "c9f1b201-e84d-408e-a758-0eb66937184b"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter LLM provider api key:··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "serper_dev_key = getpass.getpass(\"Enter serperdev api key:\")\n",
        "services_auth = {\"SerperDev\":serper_dev_key}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uqGsQrRYJZ-2",
        "outputId": "7ef165c3-e139-4dd1-ca9b-70ce9eabf384"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter serperdev api key:··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Retrieval step - service invocation\n",
        "\n",
        "Based on the prompt, retrieve the right service spec from Qdrant, inject spec and system prompt into the pipeline"
      ],
      "metadata": {
        "id": "X4uOPWS-lq2J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "invoke_service_pipe = Pipeline()\n",
        "invoke_service_pipe.add_component(\"functions_llm\", GPTChatGenerator(api_key=llm_api_key, model_name=\"gpt-3.5-turbo-0613\"))\n",
        "invoke_service_pipe.add_component(\"openapi_container\", OpenAPIServiceConnector(services_auth))\n",
        "invoke_service_pipe.connect(\"functions_llm.replies\", \"openapi_container.messages\")"
      ],
      "metadata": {
        "id": "L7MZib9gJ4j-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_prompt = \"Search web and tell me why was Sam Altman ousted from OpenAI\"\n",
        "# user_prompt = \"Compare branches main and openapi_container_v5, in project deepset-ai, repo haystack\""
      ],
      "metadata": {
        "id": "AF25DrntJ1mP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "top_k = 1\n",
        "top_k_result = retrieval_pipeline.run(data={\"text\": user_prompt, \"top_k\": top_k})\n",
        "top_k_docs = top_k_result[\"retriever\"][\"documents\"][:top_k]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "683c205f5cd24df5aa62b64047c8a6ee",
            "61da958809274b469742694e5a043f25",
            "34c692e4bfbc46189bb53a794e449734",
            "c56bac068a254edb95b9a955527eb5c3",
            "4d0909e27c7e499d92870a056fa3a086",
            "9a91fcb7874e4dd78b0a9a07ce6e8844",
            "2cc30b34a73e4638a2b21e8259417414",
            "7966660b155741d0b0c26d806d5e4c6a",
            "302e10f5434e424fb74453984255733b",
            "48baef18d7c74d29856830904fdc8894",
            "ce9b6ad2b7874f0e81582d17a23366dc"
          ]
        },
        "id": "3z568P4FJ_XU",
        "outputId": "19a5dfe7-c98e-4375-abaa-1be7d87dac9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "683c205f5cd24df5aa62b64047c8a6ee"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "top_1_document = top_k_docs[0]\n",
        "openai_functions_definition = json.loads(top_1_document.content)\n",
        "openapi_spec = top_1_document.meta[\"spec\"]\n",
        "\n",
        "service_response = invoke_service_pipe.run(data={\"messages\":[ChatMessage.from_user(user_prompt)],\n",
        "                                                 \"generation_kwargs\": {\"functions\": [openai_functions_definition]},\n",
        "                                                 \"service_openapi_spec\": openapi_spec})"
      ],
      "metadata": {
        "id": "OHP2Nj79KCdQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Generate LLM response\n",
        "\n",
        "Inject service response into LLM context, pair it with system prompt"
      ],
      "metadata": {
        "id": "S9pPCVzwmHpj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gen_pipe = Pipeline()\n",
        "llm = GPTChatGenerator(api_key=llm_api_key, model_name=\"gpt-4-1106-preview\", streaming_callback=default_streaming_callback)\n",
        "gen_pipe.add_component(\"llm\", llm)\n",
        "\n",
        "github_pr_prompt_messages = [ChatMessage.from_system(top_1_document.meta[\"system_message\"])] + service_response[\"openapi_container\"][\"service_response\"]\n",
        "final_result = gen_pipe.run(data={\"messages\": github_pr_prompt_messages})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CnYwWtYSKFl0",
        "outputId": "147fe144-ad5d-489f-aed6-fcccaad75a08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sam Altman was ousted from his position as CEO of OpenAI by the company's board. The decision was based on concerns that Altman was too focused on building OpenAI's business while not paying enough attention to the dangers of artificial intelligence. This move was surprising to many industry allies and rank-and-file employees who supported the charismatic founder. However, it has been reported that Altman was not consistently candid in his communications with the board, which also played a role in his firing.\n",
            "\n",
            "After his ouster, there were discussions about bringing him back to OpenAI, but these efforts failed, and instead, Altman was hired by Microsoft just hours after OpenAI confirmed that he would not be returning as CEO."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Thank you, questions?\n",
        "\n",
        "<a href=\"www.qr-code-generator.com/\" border=\"0\" style=\"cursor:default\" rel=\"nofollow\"><img src=\"https://chart.googleapis.com/chart?cht=qr&chl=https%3A%2F%2Fgithub.com%2Fvblagoje%2Fnotebooks%2Fblob%2Fmain%2Fhaystack2x-demos%2Fhaystack_rag_services_demo.ipynb&chs=180x180&choe=UTF-8&chld=L|2\"></a>"
      ],
      "metadata": {
        "id": "PLVhdFF06_p5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Links:\n",
        "- https://github.com/deepset-ai/haystack/\n",
        "- https://haystack.deepset.ai/community\n",
        "- https://haystack.deepset.ai/advent-of-haystack\n",
        "- https://x.com/vladblagoje"
      ],
      "metadata": {
        "id": "sD3JS7ds7IJ2"
      }
    }
  ]
}