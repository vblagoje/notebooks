{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyOFzHPT9uhEa8K3bxtyJrBx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vblagoje/notebooks/blob/main/haystack2x-experiments/chat_hf_local_summarize_graham.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y haystack-ai llmx transformers"
      ],
      "metadata": {
        "id": "3CIYnI26hKeE",
        "outputId": "702bdac0-3daf-4ea7-c757-5103ac8ce47a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: haystack-ai 2.0.0b4\n",
            "Uninstalling haystack-ai-2.0.0b4:\n",
            "  Successfully uninstalled haystack-ai-2.0.0b4\n",
            "\u001b[33mWARNING: Skipping llmx as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mFound existing installation: transformers 4.37.0.dev0\n",
            "Uninstalling transformers-4.37.0.dev0:\n",
            "  Successfully uninstalled transformers-4.37.0.dev0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q autoawq accelerate git+https://github.com/huggingface/transformers.git git+https://github.com/deepset-ai/haystack.git@hf_chat_support"
      ],
      "metadata": {
        "id": "NQ6qMjpsSbBc",
        "outputId": "1ddbf46c-4d6b-4aa5-c62d-461e71eaaea3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for haystack-ai (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "from haystack.components.generators.utils import default_streaming_callback\n",
        "from haystack.components.builders import DynamicChatPromptBuilder\n",
        "from haystack.components.fetchers import LinkContentFetcher\n",
        "from haystack.components.converters import HTMLToDocument\n",
        "from haystack.components.generators.chat import HuggingFaceLocalChatGenerator\n",
        "from haystack.dataclasses import ChatMessage\n",
        "from haystack import Pipeline"
      ],
      "metadata": {
        "id": "qZE_yF23RC9B"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lcf = LinkContentFetcher(user_agents=[\"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36\"])\n",
        "html_converter = HTMLToDocument(extractor_type=\"ArticleExtractor\")\n",
        "\n",
        "prompt_builder = DynamicChatPromptBuilder(runtime_variables=[\"documents\"])"
      ],
      "metadata": {
        "id": "UzV94CbomLJU"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = HuggingFaceLocalChatGenerator(model=\"TheBloke/OpenHermes-2.5-Mistral-7B-16k-AWQ\",\n",
        "                                    huggingface_pipeline_kwargs={\"device_map\": \"auto\"},\n",
        "                                    streaming_callback=default_streaming_callback)"
      ],
      "metadata": {
        "id": "kLzMw-zKRFvA"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipe = Pipeline()\n",
        "pipe.add_component(\"fetcher\", lcf)\n",
        "pipe.add_component(\"converter\", html_converter)\n",
        "pipe.add_component(\"prompt_builder\", prompt_builder)\n",
        "pipe.add_component(\"llm\", llm)\n",
        "\n",
        "\n",
        "pipe.connect(\"fetcher.streams\", \"converter.sources\")\n",
        "pipe.connect(\"converter.documents\", \"prompt_builder.documents\")\n",
        "pipe.connect(\"prompt_builder.prompt\", \"llm.messages\")"
      ],
      "metadata": {
        "id": "UtsgW1Adm8_M"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "template_prefix = \"\"\"Given the article below: \\n\n",
        "            {% for document in documents %}\n",
        "                {{ document.content }}\n",
        "            {% endfor %}\n",
        "            {{prompt_suffix}}\n",
        "            \"\"\"\n",
        "\n",
        "messages = [ChatMessage.from_user(template_prefix)]\n"
      ],
      "metadata": {
        "id": "D1GsXe82pw8w"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = pipe.run(data={\"urls\": [\"https://www.paulgraham.com/superlinear.html\"],\n",
        "                        \"prompt_source\": messages,\n",
        "                        \"template_variables\": {\"prompt_suffix\" : \"Summarize the main takeaways and learnings in a few key bullet points\"},\n",
        "                        \"generation_kwargs\": {\"prompt_lookup_num_tokens\": 10}})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UQT2zU9AibSS",
        "outputId": "990bcfe0-e477-4c1c-ccd9-49485e86db57"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- Superlinear returns refer to the concept where the rewards for performance are disproportionately higher than the effort put in.\n",
            "- The author believes that understanding superlinear returns is crucial for ambitious individuals to succeed in today's world.\n",
            "- Two main causes of superlinear returns are exponential growth and thresholds.\n",
            "- Exponential growth can lead to thresholds and vice versa.\n",
            "- Work that compounds directly (doing well in one cycle causes you to do better in the next) and work that compounds through learning are the most promising.\n",
            "- Ambitious people should take advantage of superlinear returns by doing exceptional work, choosing work they are interested in, and following their curiosity.\n",
            "- The list of fields with superlinear returns includes sports, politics, art, music, directing, math, starting companies, and investing.\n",
            "- Superlinear returns imply inequality, with a few big winners outperforming everyone else.\n",
            "- The territory of superlinear returns can expand, making it powerful.\n",
            "- The most extreme returns come from expanding the territory.\n",
            "- Superlinear returns are not limited to effort, performance, and return, but can also be applied to learning.\n",
            "- The author suggests that the most ambitious individuals should focus on independent-minded fields with superlinear returns.\n",
            "- The author believes that the shift away from institutions will lead to more variation in outcomes.\n",
            "- The list of fields with superlinear returns also shows that work is not always equal to a job.\n",
            "- The world has changed dramatically in the last century, with more opportunities for ambitious individuals.\n",
            "- The author suggests that the concept of superlinear returns is not static and will continue to evolve.<|im_end|>\n"
          ]
        }
      ]
    }
  ]
}