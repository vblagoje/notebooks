{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyNbqZKXcoVPN1G4InroheQK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vblagoje/notebooks/blob/main/haystack2x-experiments/chat_hf_local_summarize_graham.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y haystack-ai llmx transformers"
      ],
      "metadata": {
        "id": "3CIYnI26hKeE",
        "outputId": "8b35df5f-ecd9-49e4-e230-a05a3abce2ac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: haystack-ai 2.0.0b4\n",
            "Uninstalling haystack-ai-2.0.0b4:\n",
            "  Successfully uninstalled haystack-ai-2.0.0b4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q accelerate git+https://github.com/huggingface/transformers.git git+https://github.com/deepset-ai/haystack.git@hf_chat_support"
      ],
      "metadata": {
        "id": "NQ6qMjpsSbBc",
        "outputId": "19ac98fa-62a3-4833-bca2-28fe3b3eb2d6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "from haystack.components.generators.utils import default_streaming_callback\n",
        "from haystack.components.builders import DynamicChatPromptBuilder\n",
        "from haystack.components.fetchers import LinkContentFetcher\n",
        "from haystack.components.converters import HTMLToDocument\n",
        "from haystack.components.generators.chat import HuggingFaceLocalChatGenerator\n",
        "from haystack.dataclasses import ChatMessage\n",
        "from haystack import Pipeline"
      ],
      "metadata": {
        "id": "qZE_yF23RC9B"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lcf = LinkContentFetcher(user_agents=[\"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36\"])\n",
        "html_converter = HTMLToDocument(extractor_type=\"ArticleExtractor\")\n",
        "\n",
        "template = \"\"\"Given the information below: \\n\n",
        "            {% for document in documents %}\n",
        "                {{ document.content }}\n",
        "            {% endfor %}\n",
        "            Answer question: {{ query }}. \\n Answer:\"\"\"\n",
        "\n",
        "prompt_builder = DynamicChatPromptBuilder(runtime_variables=[\"documents\"])"
      ],
      "metadata": {
        "id": "UzV94CbomLJU"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = HuggingFaceLocalChatGenerator(model=\"HuggingFaceH4/zephyr-7b-alpha\",\n",
        "                                    huggingface_pipeline_kwargs={\"device_map\": \"auto\"},\n",
        "                                    streaming_callback=default_streaming_callback)"
      ],
      "metadata": {
        "id": "kLzMw-zKRFvA"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipe = Pipeline()\n",
        "pipe.add_component(\"fetcher\", lcf)\n",
        "pipe.add_component(\"converter\", html_converter)\n",
        "pipe.add_component(\"prompt_builder\", prompt_builder)\n",
        "pipe.add_component(\"llm\", llm)\n",
        "\n",
        "\n",
        "pipe.connect(\"fetcher.streams\", \"converter.sources\")\n",
        "pipe.connect(\"converter.documents\", \"prompt_builder.documents\")\n",
        "pipe.connect(\"prompt_builder.prompt\", \"llm.messages\")"
      ],
      "metadata": {
        "id": "UtsgW1Adm8_M"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "template_prefix = \"\"\"Given the article below: \\n\n",
        "            {% for document in documents %}\n",
        "                {{ document.content }}\n",
        "            {% endfor %}\n",
        "            {{prompt_suffix}}\n",
        "            \"\"\"\n",
        "\n",
        "messages = [ChatMessage.from_user(template_prefix)]\n"
      ],
      "metadata": {
        "id": "D1GsXe82pw8w"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = pipe.run(data={\"urls\": [\"https://www.paulgraham.com/getideas.html\"],\n",
        "                        \"prompt_source\": messages,\n",
        "                        \"template_variables\": {\"prompt_suffix\" : \"Summarize the main takeaways and learnings\"},\n",
        "                        \"generation_kwargs\": {\"prompt_lookup_num_tokens\": 10}})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UQT2zU9AibSS",
        "outputId": "978fb512-2a1e-4e23-caa0-54e2a04cfe67"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The main takeaways and learnings from the article are:\n",
            "\n",
            "1. To get new ideas, look for anomalies or gaps in knowledge, especially at the frontiers of knowledge.\n",
            "2. Knowledge grows fractally, meaning that its edges may appear smooth from a distance, but up close, there are gaps and anomalies that seem obvious and inexplicable.\n",
            "3. Exploring these gaps can yield whole new fractal buds, which can lead to significant discoveries and advancements.\n",
            "\n",
            "In summary, the article suggests that noticing anomalies and gaps in knowledge is a key strategy for generating new ideas and driving innovation.</s>\n"
          ]
        }
      ]
    }
  ]
}